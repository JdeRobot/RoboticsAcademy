<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.16.5 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Visual Odometry with RGBD - Robotics-Academy</title>
<meta name="description" content="A practical and fun way of learning Robotics and Computer Vision">



<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Robotics-Academy">
<meta property="og:title" content="Visual Odometry with RGBD">
<meta property="og:url" content="http://localhost:4000/exercises/ComputerVision/visual_odometry">












  

  


<link rel="canonical" href="http://localhost:4000/exercises/ComputerVision/visual_odometry">







  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "JdeRobot",
      "url": "http://localhost:4000",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Robotics-Academy Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE ]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link rel="icon" type="image/png" href="/assets/images/logo.png" sizes="16x16">
<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/logo.png" alt=""></a>
        
        <a class="site-title" href="/">
          Robotics-Academy
          <span class="site-subtitle">by JdeRobot organization</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/exercises/" >Exercises</a>
            </li><li class="masthead__menu-item">
              <a href="/installation/" >Installation</a>
            </li><li class="masthead__menu-item">
              <a href="https://forum.jderobot.org/c/english/roboticsacademy" >Forum</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name"></h3>
    
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle Menu</label>
  <ul class="nav__items">
    
      <li>
        
          
          

          <a href="/exercises/"><span class="nav__sub-title">Exercises</span></a>
        

        
        <ul>
          
            
            

            
            

            <li><a href="/exercises/autonomous_cars_section" class="">Autonomous Driving</a></li>
          
            
            

            
            

            <li><a href="/exercises/mobile_robots_section" class="">Service Robots</a></li>
          
            
            

            
            

            <li><a href="/exercises/drones_section" class="">Drones</a></li>
          
            
            

            
            

            <li><a href="/exercises/computer_vision_section" class="">Computer Vision</a></li>
          
            
            

            
            

            <li><a href="/exercises/industrial_robots_section" class="">Industrial Robots</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Contribute</span>
        

        
        <ul>
          
            
            

            
            

            <li><a href="/roadmap/" class="">Roadmap</a></li>
          
            
            

            
            

            <li><a href="/contribute/" class="">How to contribute</a></li>
          
        </ul>
        
      </li>
    
  </ul>
</nav>
    
  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Visual Odometry with RGBD">
    
    
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Visual Odometry with RGBD
</h1>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right ">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-cog"></i> TOC Visual Odometry with RGBD</h4></header>
              <ul class="toc__menu">
  <li><a href="#installation">Installation</a></li>
  <li><a href="#how-to-run">How to run</a></li>
  <li><a href="#how-to-do-the-practice">How to do the practice:</a>
    <ul>
      <li><a href="#where-to-insert-the-code">Where to insert the code</a></li>
      <li><a href="#apis">API’s:</a></li>
    </ul>
  </li>
  <li><a href="#data-types">Data Types:</a></li>
  <li><a href="#theory">Theory</a></li>
  <li><a href="#hint">Hint</a></li>
  <li><a href="#demonstration-video">Demonstration video:</a></li>
  <li><a href="#contributors">Contributors</a></li>
</ul>
            </nav>
          </aside>
        
        <p>The objective of this exercise is to implement the logic of a RGBD visual odometry algorithm. The performance/accuracy of the users’ algorithm will be shown on the GUI of the exercise.</p>

<figure class=" ">
  
    
      <a href="/assets/images/exercises/visual_odometry/vo.png" title="Visual Odometry.">
        <img src="/assets/images/exercises/visual_odometry/vo.png" alt="Visual Odometry." />
      </a>
    
  
  
    <figcaption>Gallery.
</figcaption>
  
</figure>

<h2 id="installation">Installation</h2>

<ul>
  <li>
    <p><strong>Requirements</strong> - (install these packages before proceeding).</p>

    <p>pyqtgraph  — <code class="language-plaintext highlighter-rouge">sudo pip install pyqtgraph</code></p>

    <p>configparser — <code class="language-plaintext highlighter-rouge">sudo pip install configparser</code></p>
  </li>
</ul>

<h2 id="how-to-run">How to run</h2>

<p>To launch the exercise, follow the steps below:</p>

<ul>
  <li>
    <p><strong>Download</strong> the rosbag file from here. <a href="https://gsyc.urjc.es/jmplaza/slam/rgbd_dataset_freiburg2_pioneer_slam_truncated.bag">https://gsyc.urjc.es/jmplaza/slam/rgbd_dataset_freiburg2_pioneer_slam_truncated.bag</a></p>
  </li>
  <li>
    <p><strong>Place</strong> the rosbag file in the same directory as of this exercise and replace the name of the rosbag file in the <strong>‘visual_odometry.cfg’</strong> or mention the full path of the rosbag file.</p>
  </li>
  <li>
    <p><strong>Execute</strong> the exercise with GUI : <code class="language-plaintext highlighter-rouge">python visual_odom.py</code></p>
  </li>
</ul>

<h2 id="how-to-do-the-practice">How to do the practice:</h2>
<p>To carry out the practice, you must edit the MyAlgorithm.py file and insert the algorithm logic into it.</p>

<h3 id="where-to-insert-the-code">Where to insert the code</h3>
<p><a href="MyAlgorithm.py#L93">MyAlgorithm.py</a></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    def execute(self):
        # demo code (replace with your code )
        print ("Runing")

        #Getting sensor data 
        data = self.getReadings( 'color_img' , 'depth_img' )

        #color image 
        color_image = data.color_img 

        #depth image 
        depth_image = data.depth_img 

        #set processed image
        self.set_processed_image(color_img)

        #set predicted pose
        x = 1
        y = 1
        self.set_predicted_pose(x,y,timestamp) #timestamp of the predicted position. 
        
</code></pre></div></div>

<h3 id="apis">API’s:</h3>

<p><strong>Sensors available:</strong> - ‘color_img’ , ‘depth_img’, ‘orientation’ , ‘accelerometer’ , ‘scan’ (laser scan) .</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">data = self.getReadings('color_img' , 'depth_img')</code>  - to get the next available RGB image and the Depth image from the ROSbag file. ( only one pair of RGB image and Depth image will be provided per call).</p>
  </li>
  <li><code class="language-plaintext highlighter-rouge">color_img = data.color_img</code> - to get the RGB image from the object ‘data’.</li>
  <li><code class="language-plaintext highlighter-rouge">depth_img = data.depth_img</code> - to get the Depth image from the object ‘data’.</li>
  <li><code class="language-plaintext highlighter-rouge">color_img_t = data.color_img_t</code> - to get the timestamp of the RGB image.</li>
  <li><code class="language-plaintext highlighter-rouge">depth_img_t = data.depth_img_t</code> - to get the timestamp of the Depth image.</li>
</ul>

<p><strong>Similarly ,</strong> to get the readings of other sensors the required sensors name has to be mentioned while calling <code class="language-plaintext highlighter-rouge">data = self.getReadings()</code>  separated by commas (,).</p>

<p><code class="language-plaintext highlighter-rouge">data.color_img</code> - for RGB color image and <code class="language-plaintext highlighter-rouge">data.color_img_t</code> for its timestamp.</p>

<p><code class="language-plaintext highlighter-rouge">data.depth_img</code> - for depth image and <code class="language-plaintext highlighter-rouge">data.depth_img_t</code> for its timestamp.</p>

<p><code class="language-plaintext highlighter-rouge">data.accelerometer</code> - for accelerometer data and <code class="language-plaintext highlighter-rouge">data.accelerometer_t</code> for its timestamp.</p>

<p><code class="language-plaintext highlighter-rouge">data.orientation</code> - for orientation data and <code class="language-plaintext highlighter-rouge">data.orientation_t</code> for its timestamp.</p>

<p><code class="language-plaintext highlighter-rouge">data.scan</code> - for laser scan data and <code class="language-plaintext highlighter-rouge">data.scan_t</code> for its timestamp.</p>

<p>(You can mention as many as sensors names during calling the <code class="language-plaintext highlighter-rouge">data = self.getReadings()</code> method).</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">self.set_processed_image(color_img)</code>  - to set the processed RGB image to be shown on the GUI.</li>
  <li><code class="language-plaintext highlighter-rouge">self.set_predicted_pose(x,y,timestamp)</code>  - to set the position and timestamp of the predict pose by the algorithm ( x and y should be floating point number.)</li>
  <li><code class="language-plaintext highlighter-rouge">self.set_predicted_path(path)</code>  - to set predicted path at once /or reset the previously set predicted poses at once —- path should be Nx2 (numpy array or python list) [x,y]. <em>(optional)</em></li>
</ul>

<p><strong>How does data from multiple sensors are read and provided to the users by the <code class="language-plaintext highlighter-rouge">self.getReadings()</code> method?</strong></p>

<p>Let’s assume that the user only wants the data from ‘color_img’ , ‘depth_img’ and ‘scan’ sensors. So the user will call the method like this <code class="language-plaintext highlighter-rouge">data = self.getReadings('color_img' , 'depth_img','scan')</code> . Internally the program then starts to read the messages ROSbag file chronologically and if any of the above mentioned sensor topic is found , the topic data gets stored in its respective attribute.The program continues to read the topics in ROSbag file sequentially until all the sensor data required by the user are read and stored in its respective attributes. And since the data frequency of different sensors are different so while reading the sensor data sequentially the latest data from a particular sensor will override it’s previous value.</p>

<p><strong>REMEMBER :</strong> By this method only the sensor name mentioned while calling this method will have the sensor data . e.g. - In the above example (<code class="language-plaintext highlighter-rouge">data = self.getReadings('color_img' , 'depth_img','scan')</code> ) only <code class="language-plaintext highlighter-rouge">data.color_img</code> , <code class="language-plaintext highlighter-rouge">data.depth_img</code> and <code class="language-plaintext highlighter-rouge">data.scan</code> will contain its’ respective sensor data and other attributes like <code class="language-plaintext highlighter-rouge">data.accelerometer</code> and <code class="language-plaintext highlighter-rouge">data.orientation</code> will contain <code class="language-plaintext highlighter-rouge">NoneType</code> data.</p>

<figure class=" ">
  
    
      <a href="/assets/images/exercises/visual_odometry/RGBD_img.png" title="RGBD">
        <img src="/assets/images/exercises/visual_odometry/RGBD_img.png" alt="RGBD" />
      </a>
    
  
  
    <figcaption>RGB with Depth
</figcaption>
  
</figure>

<h2 id="data-types">Data Types:</h2>
<ul>
  <li>The Color RGB image is provided in 640×480 8-bit RGB format.</li>
  <li>The Depth image is provided in 32-bit floating point precision.</li>
  <li>The Timestamps are floating point numbers.</li>
  <li>The laser scan data is provided in numpy array format.</li>
  <li>
    <p>Orientation data can be accessed as follows:</p>

    <p>qz = data.orientation[‘qz’]</p>

    <p>qw = data.orientation[‘qw’]</p>

    <p>‘qx’ and ‘qy’ are essentially zero(since we are computing 2D odometry).</p>
  </li>
  <li>
    <p>Accelerometer data can be accessed as follows:</p>

    <p>ax = data.accelerometer[‘x’]</p>

    <p>ay = data.accelerometer[‘y’]</p>

    <p>‘az’ is essentially zero(since we are computing 2D odometry).</p>
  </li>
  <li>For more details about the dataset refer to the original page of the TUM RGBD dataset <a href="https://vision.in.tum.de/data/datasets/rgbd-dataset/file_formats#ros_bag">https://vision.in.tum.de/data/datasets/rgbd-dataset/file_formats#ros_bag</a>.</li>
</ul>

<h2 id="theory">Theory</h2>

<ul>
  <li>Visual Odometry is the process of incrementally estimating the pose of the vehicle by examining the changes that motion induces on the images of its onboard cameras.</li>
  <li>Contrary to wheel odometry, VO is not affected by wheel slip in uneven terrain or other adverse conditions.</li>
  <li>More accurate trajectory estimates compared to wheel odometry .</li>
  <li>VO computes the camera path incrementally (pose after pose).</li>
</ul>

<p>Here is a flowchart explaining the step-by-step process for implementing an visual odometry algorithm.</p>

<figure class=" ">
  
    
      <a href="/assets/images/exercises/visual_odometry/flow.PNG" title="Flowchart">
        <img src="/assets/images/exercises/visual_odometry/flow.PNG" alt="flowchart" />
      </a>
    
  
  
    <figcaption>Flowchart
</figcaption>
  
</figure>

<p>More detailed deliberation on visual odometry is provided here.</p>

<p>1) <a href="https://sites.google.com/site/scarabotix/tutorial-on-visual-odometry/">https://sites.google.com/site/scarabotix/tutorial-on-visual-odometry/</a></p>

<p>2) <a href="http://www.cs.toronto.edu/~urtasun/courses/CSC2541/03_odometry.pdf">http://www.cs.toronto.edu/~urtasun/courses/CSC2541/03_odometry.pdf</a></p>

<h2 id="hint">Hint</h2>

<p>Simple hints provided to help you solve the exercise. Please note that the <strong>following hint is only a suggestive approach. Any other algorithm to solve the exercise is acceptable.</strong></p>

<p>1) Detect features from the first available RGB image using FAST algorithm.</p>

<p>2) Track the detected features in the next available RGB image using Lucas-Kanade Optical Flow Algorithm.</p>

<p>3) Create the 3D pointcloud (of the tracked/detected feature points) of the latest two available RGB image with the help of their depth image .</p>

<p>4) Estimate the motion between two consecutive 3D pointclouds.</p>

<p>5) Concatenate the Rotation and Translational information to obtain the predicted path.</p>

<p>Following research paper can be used as a reference:
<a href="https://link.springer.com/chapter/10.1007/978-3-319-29363-9_14">Visual Odometry and Mapping for Autonomous Flight Using an RGB-D Camera</a></p>

<h2 id="demonstration-video">Demonstration video:</h2>

<div class="embed-container">
  <iframe src="https://www.youtube.com/embed/HUFOadsCSRo" width="700" height="480" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<h2 id="contributors">Contributors</h2>

<ul>
  <li>
    <p>Contributors: <a href="https://github.com/dattadebrup">Debrup Datta</a>, <a href="https://github.com/jmplaza">Jose María Cañas</a></p>
  </li>
  <li>
    <p>Maintained by <a href="https://github.com/dattadebrup">Debrup Datta</a>.</p>
  </li>
</ul>

        
      </section>

      <footer class="page__meta">
        
        


        
      </footer>

      

      
    </div>

    
  </article>

  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/jderobot" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/JdeRobot/RoboticsAcademy" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
      
        
          <li><a href="https://www.youtube.com/channel/UCgmUgpircYAv_QhLQziHJOQ" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-youtube" aria-hidden="true"></i> Youtube</a></li>
        
      
    

   <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2021 JdeRobot. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>


      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://kit.fontawesome.com/4eee35f757.js"></script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
  </script>
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       extensions: ["tex2jax.js"],
       jax: ["input/TeX", "output/HTML-CSS"],
       tex2jax: {
         inlineMath: [ ['$','$'], ["\\(","\\)"] ],
         displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
         processEscapes: true
       },
       "HTML-CSS": { availableFonts: ["TeX"] }
     });
  </script>










  </body>
</html>
